{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn import preprocessing\n",
    "from gensim.models import Word2Vec\n",
    "import seaborn as sns\n",
    "import jieba\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 01.è¯»å–æ•°æ®"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "hole_df = pd.read_csv(\"../data/2023-06-08_holes_day.csv\", index_col=0)\n",
    "hole_df.dropna(inplace=True)\n",
    "hole_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hole_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hole_df['reply'] = hole_df.reply.astype(float)\n",
    "hole_df['likenum'] = hole_df.likenum.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hole_df['hot'] = hole_df.likenum*hole_df.reply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hole_df.sort_values('hot').tail(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hole_df.loc[:,'hour'] = hole_df.time.apply(lambda x: x.split()[1].split(':')[0]).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hole_df.groupby('hour').count().text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set()\n",
    "sns.lineplot(hole_df.groupby('hour').count().text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(hole_df.groupby('hour').hot.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hole_df = hole_df[hole_df['hot'] != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "#ç”±äºç­›å‡ºæ¥å¤ªå¤šæ— æ„ä¹‰åœæ­¢è¯ï¼Œæ‰€ä»¥åŠ å…¥åœæ­¢è¯è¡¨ https://raw.githubusercontent.com/goto456/stopwords/master/baidu_stopwords.txt\n",
    "with open(\"baidu_stopwords.txt\") as f:\n",
    "    stop_word_list = f.read().splitlines()\n",
    "useless_str = '''ä¸€ï¼â€œâ€ï¼Œã€‚ï¼Ÿã€ï¼›â€™\"',.ã€Â·ã€Šã€‹ï¼ˆï¼‰()#\\tï¼š\\n\\r\\n/'''\n",
    "\n",
    "words = hole_df['text'].progress_apply(lambda x: ' '.join([x for x in jieba.cut(x) if x not in stop_word_list and x not in useless_str]))\n",
    "hole_df['raw_text'] = hole_df['text'].copy()\n",
    "hole_df['text'] = words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter\n",
    "# hole_df = hole_df.loc[(hole_df.hour<=2) | (hole_df.hour>=23),:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hole_df.loc[:,'hot_norm'] = hole_df.hot.apply(lambda x: x if x==0 else np.log(x))\n",
    "hole_df.loc[:,'hot_norm'] = hole_df.hot_norm.apply(lambda x: x if x!=0 else 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hot_hole = hole_df[hole_df.hot_norm>1]\n",
    "hot_hole.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfi_hole_adj = pd.concat([hole_df, hot_hole, hot_hole], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer()\n",
    "tfidf_vec = tfidf.fit_transform(tfi_hole_adj['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the feature names from the vectorizer\n",
    "feature_names = tfidf.get_feature_names_out()\n",
    "\n",
    "# Get the sum of the tf-idf values for each feature across all documents\n",
    "sum_tfidf = np.sum(tfidf_vec.toarray(), axis=0)\n",
    "\n",
    "# Get the indices of the features sorted by their tf-idf sum in descending order\n",
    "sorted_indices = np.argsort(sum_tfidf)[::-1]\n",
    "\n",
    "# Print the top 10 features and their tf-idf sums\n",
    "print(\"Top 10 features and their tf-idf sums\")\n",
    "for i in range(10):\n",
    "    feature_index = sorted_indices[i]\n",
    "    feature_name = feature_names[feature_index]\n",
    "    tfidf_sum = sum_tfidf[feature_index]\n",
    "    print(f\"{feature_name}: {tfidf_sum}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word2Vec vectorization for segmented 'ç®€ä»‹'\n",
    "sentences = [s.split() for s in hole_df['text']]\n",
    "\n",
    "seed = 123\n",
    "w2v = Word2Vec(sentences, vector_size=10, min_count=1, workers=4, seed=seed) # size is the dimensionality of the feature vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for e in w2v.wv.most_similar(positive=['é£Ÿå ‚'], topn=10):\n",
    "   print(e[0], e[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We first tokenize each sentence in the storyline column\n",
    "tokenized_sentences = hole_df.text.apply(lambda x: x.split())\n",
    "\n",
    "# We then calculate the word vectors for each word in each sentence\n",
    "word_vectors = tokenized_sentences.apply(lambda x: np.array([w2v.wv[word] for word in x if word in w2v.wv.key_to_index]))\n",
    "\n",
    "# We then calculate the average vector for each sentence\n",
    "sentence_vectors = word_vectors.apply(lambda x: np.mean(x, axis=0)) \n",
    "\n",
    "# The resulting sentence_vectors will contain the vector representation for each sentence in the storyline column.\n",
    "sentence_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "corpus = [\n",
    "    'This is the first document.',\n",
    "    'This document is the second document.',\n",
    "    'And this is the third one.',\n",
    "    'Is this the first document?',\n",
    "]\n",
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "vectorizer.get_feature_names_out()\n",
    "\n",
    "\n",
    "X.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_sentence_vectors = np.stack(np.array(sentence_vectors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_sentence_vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hole_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hole_df.loc[:,'hour_6am'] = hole_df.hour.apply(lambda x: x-6 if x-6 >= 0 else x-6+24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = np.array(hole_df[['reply', 'likenum', 'hour_6am']])\n",
    "train_data = np.hstack([train_data, w2v_sentence_vectors])\n",
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "train_data = scaler.fit_transform(train_data)\n",
    "pca_train = PCA(n_components=0.95)\n",
    "train_data_pca = pca_train.fit_transform(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the scree plot\n",
    "plt.plot(range(1, pca_train.n_components_ + 1), pca_train.explained_variance_ratio_.cumsum(), marker='o')\n",
    "plt.xlabel('Number of components')\n",
    "plt.ylabel('Cumulative explained variance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 3: K-means clustering\n",
    "\n",
    "# Elbow method to determine optimal number of clusters\n",
    "# Calculate the sum of squared errors for different values of k\n",
    "# Choose the value of k at the \"elbow\" of the plot\n",
    "# This is the point of diminishing returns, where adding more clusters doesn't significantly improve the SSE\n",
    "# Set the value of k to the optimal number of clusters\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Calculate SSE for different values of k\n",
    "sse = []\n",
    "for k in range(1, 11):\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42, n_init='auto')\n",
    "    kmeans.fit(train_data_pca)\n",
    "    sse.append(kmeans.inertia_)\n",
    "\n",
    "# Plot SSE against number of clusters\n",
    "plt.plot(range(1, 11), sse)\n",
    "plt.title('Elbow Method')\n",
    "plt.xlabel('Number of Clusters')\n",
    "plt.ylabel('SSE')\n",
    "plt.show()\n",
    "\n",
    "# Set the value of k to the optimal number of clusters\n",
    "k = 30\n",
    "\n",
    "# Perform K-means clustering with optimal number of clusters\n",
    "kmeans = KMeans(n_clusters=k, random_state=114514, n_init='auto')\n",
    "kmeans.fit_transform(train_data_pca)\n",
    "# Use the trained KMeans model to predict the cluster labels for the test data\n",
    "labels = kmeans.labels_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary to store the holes in each cluster\n",
    "cluster_holes = {}\n",
    "for i in range(k):\n",
    "    cluster_holes[i] = []\n",
    "\n",
    "# Iterate through the test data and add each movie to its corresponding cluster\n",
    "for i in range(len(train_data_pca)):\n",
    "    cluster_holes[labels[i]].append(hole_df.iloc[i])\n",
    "\n",
    "# Output representative movies, number of movies in each cluster, and rating distribution\n",
    "cluster_avg_hour_6am = []\n",
    "cluster_avg_like = []\n",
    "cluster_avg_reply = []\n",
    "for i in range(k):\n",
    "    print(\"====================\")\n",
    "    print(f\"Cluster {i+1}:\")\n",
    "    print(f\"Number of holes in cluster: {len(cluster_holes[i])}\")\n",
    "    print(f\"Avg time(start at 6am) {hole_df[labels == i]['hour_6am'].mean()}\")\n",
    "    cluster_avg_hour_6am.append(hole_df[labels == i]['hour_6am'].mean())\n",
    "    print(f\"Like mean: {hole_df[labels == i]['likenum'].mean()}\")\n",
    "    cluster_avg_like.append(hole_df[labels == i]['likenum'].mean())\n",
    "    print(f\"Reply mean: {hole_df[labels == i]['reply'].mean()}\")\n",
    "    cluster_avg_reply.append(hole_df[labels == i]['reply'].mean())\n",
    "    # Print the tags for each movie in the cluster\n",
    "    print(f\"Text for hole: {hole_df[labels == i]['raw_text'].sample(10)}\")\n",
    "\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_path = '/datb1/wuyuxuan/tmp/Holemonitor/data/2024-03-09_holes_monitor.db'\n",
    "with sqlite3.connect(db_path) as conn:\n",
    "    data = pd.read_sql(\"SELECT * FROM holes\", conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pid</th>\n",
       "      <th>text</th>\n",
       "      <th>type</th>\n",
       "      <th>time</th>\n",
       "      <th>reply</th>\n",
       "      <th>likenum</th>\n",
       "      <th>last_retrive</th>\n",
       "      <th>hot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1068</th>\n",
       "      <td>6037913</td>\n",
       "      <td>popi  è¯·é—®é—®é¢˜ï¼ˆä»¥åŠdzå¯èƒ½å›é—®ï¼‰</td>\n",
       "      <td>text</td>\n",
       "      <td>2024-03-10 01:01:55</td>\n",
       "      <td>92.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2024-03-10 01:27:01</td>\n",
       "      <td>736.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1126</th>\n",
       "      <td>6037971</td>\n",
       "      <td>popi ğŸ‘© éšä¾¿èŠèŠ</td>\n",
       "      <td>text</td>\n",
       "      <td>2024-03-10 01:32:15</td>\n",
       "      <td>99.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2024-03-10 02:20:22</td>\n",
       "      <td>693.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488</th>\n",
       "      <td>6037332</td>\n",
       "      <td>æ´ä¸»ä»22å¹´12æœˆâ€œç¬¬ä¸€è´£ä»»äººâ€å¼€å§‹ï¼Œå› ä¸ºå®¶å±è®¤ä¸ºæ–°å† çš„åæœè¿˜æ˜¯è¦è§‚å¯Ÿä¸€æ®µæ—¶é—´å†ä¸‹ç»“è®ºï¼Œå°±ä¸€...</td>\n",
       "      <td>text</td>\n",
       "      <td>2024-03-09 22:05:02</td>\n",
       "      <td>33.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>2024-03-09 22:23:19</td>\n",
       "      <td>462.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>6037153</td>\n",
       "      <td>æ ‘æ´çš„æœ‹å‹ä»¬å¤§å®¶å¥½ã€‚æœ‰ä¸€ä»¶äº‹æƒ…æƒ³å‘å¤§å®¶æ±‚åŠ©ï¼Œdzç°åœ¨å¾—äº†å¾ˆä¸¥é‡çš„ç—…ï¼Œå¾ˆéš¾æ²»å¥½çš„é‚£ç§ã€‚å¾ˆå¤šå¹´å‰...</td>\n",
       "      <td>text</td>\n",
       "      <td>2024-03-09 21:02:52</td>\n",
       "      <td>30.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2024-03-09 21:19:39</td>\n",
       "      <td>360.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1030</th>\n",
       "      <td>6037875</td>\n",
       "      <td>æˆ‘å¾ˆä¸å–œæ¬¢åŒ—äº¬ã€‚å®ƒç°ä»£ï¼Œå·¥æ•´ï¼Œå››å¹³å…«ç¨³ï¼Œè¿‡åˆ†åœ°å®½æ•ï¼Œæ˜¾å‡ºä¸€ç§å†·æ¼ æ¥ã€‚å†¬æ˜¥æ—¶æ˜¯æœ€è®¨åŒçš„å­£èŠ‚ï¼Œåˆ®...</td>\n",
       "      <td>text</td>\n",
       "      <td>2024-03-10 00:44:22</td>\n",
       "      <td>12.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>2024-03-10 01:06:35</td>\n",
       "      <td>336.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>577</th>\n",
       "      <td>6037421</td>\n",
       "      <td>åŸä»·20å‡ºä¸€å¼ å‘¨ä¸‰æ™šä¸Šé©¾é©¶æˆ‘çš„è½¦ äºŒæ¥¼ä¸­é—´é å</td>\n",
       "      <td>text</td>\n",
       "      <td>2024-03-09 22:33:37</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2024-03-09 22:46:29</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>580</th>\n",
       "      <td>6037424</td>\n",
       "      <td>6036526ææ é—²ç½® äºŒæ‰‹ å‡ºè¡£æœ å¤šä¹°å¯åˆ€</td>\n",
       "      <td>text</td>\n",
       "      <td>2024-03-09 22:35:29</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2024-03-09 22:49:11</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>583</th>\n",
       "      <td>6037427</td>\n",
       "      <td>æ”¶ç•™å¯çˆ±å¦¹å¦¹ï½</td>\n",
       "      <td>text</td>\n",
       "      <td>2024-03-09 22:36:20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2024-03-09 22:50:31</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>587</th>\n",
       "      <td>6037431</td>\n",
       "      <td>æœ‰ç‚¹å°ç—›è‹¦</td>\n",
       "      <td>text</td>\n",
       "      <td>2024-03-09 22:36:58</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2024-03-09 22:50:31</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1189</th>\n",
       "      <td>6038034</td>\n",
       "      <td>æ‚ æ‚ æµ®äº‘æœ›ç©¿\\r\\näººäº‹çœ‹åŒå€¦\\r\\nå”¯ç‹¬æƒ…ä¸å˜</td>\n",
       "      <td>text</td>\n",
       "      <td>2024-03-10 02:50:15</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2024-03-10 02:54:24</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1190 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          pid                                               text  type   \n",
       "1068  6037913                               popi  è¯·é—®é—®é¢˜ï¼ˆä»¥åŠdzå¯èƒ½å›é—®ï¼‰  text  \\\n",
       "1126  6037971                                        popi ğŸ‘© éšä¾¿èŠèŠ  text   \n",
       "488   6037332  æ´ä¸»ä»22å¹´12æœˆâ€œç¬¬ä¸€è´£ä»»äººâ€å¼€å§‹ï¼Œå› ä¸ºå®¶å±è®¤ä¸ºæ–°å† çš„åæœè¿˜æ˜¯è¦è§‚å¯Ÿä¸€æ®µæ—¶é—´å†ä¸‹ç»“è®ºï¼Œå°±ä¸€...  text   \n",
       "309   6037153  æ ‘æ´çš„æœ‹å‹ä»¬å¤§å®¶å¥½ã€‚æœ‰ä¸€ä»¶äº‹æƒ…æƒ³å‘å¤§å®¶æ±‚åŠ©ï¼Œdzç°åœ¨å¾—äº†å¾ˆä¸¥é‡çš„ç—…ï¼Œå¾ˆéš¾æ²»å¥½çš„é‚£ç§ã€‚å¾ˆå¤šå¹´å‰...  text   \n",
       "1030  6037875  æˆ‘å¾ˆä¸å–œæ¬¢åŒ—äº¬ã€‚å®ƒç°ä»£ï¼Œå·¥æ•´ï¼Œå››å¹³å…«ç¨³ï¼Œè¿‡åˆ†åœ°å®½æ•ï¼Œæ˜¾å‡ºä¸€ç§å†·æ¼ æ¥ã€‚å†¬æ˜¥æ—¶æ˜¯æœ€è®¨åŒçš„å­£èŠ‚ï¼Œåˆ®...  text   \n",
       "...       ...                                                ...   ...   \n",
       "577   6037421                            åŸä»·20å‡ºä¸€å¼ å‘¨ä¸‰æ™šä¸Šé©¾é©¶æˆ‘çš„è½¦ äºŒæ¥¼ä¸­é—´é å  text   \n",
       "580   6037424                           6036526ææ é—²ç½® äºŒæ‰‹ å‡ºè¡£æœ å¤šä¹°å¯åˆ€  text   \n",
       "583   6037427                                            æ”¶ç•™å¯çˆ±å¦¹å¦¹ï½  text   \n",
       "587   6037431                                              æœ‰ç‚¹å°ç—›è‹¦  text   \n",
       "1189  6038034                           æ‚ æ‚ æµ®äº‘æœ›ç©¿\\r\\näººäº‹çœ‹åŒå€¦\\r\\nå”¯ç‹¬æƒ…ä¸å˜  text   \n",
       "\n",
       "                     time  reply  likenum         last_retrive    hot  \n",
       "1068  2024-03-10 01:01:55   92.0      8.0  2024-03-10 01:27:01  736.0  \n",
       "1126  2024-03-10 01:32:15   99.0      7.0  2024-03-10 02:20:22  693.0  \n",
       "488   2024-03-09 22:05:02   33.0     14.0  2024-03-09 22:23:19  462.0  \n",
       "309   2024-03-09 21:02:52   30.0     12.0  2024-03-09 21:19:39  360.0  \n",
       "1030  2024-03-10 00:44:22   12.0     28.0  2024-03-10 01:06:35  336.0  \n",
       "...                   ...    ...      ...                  ...    ...  \n",
       "577   2024-03-09 22:33:37    0.0      1.0  2024-03-09 22:46:29    0.0  \n",
       "580   2024-03-09 22:35:29    0.0      0.0  2024-03-09 22:49:11    0.0  \n",
       "583   2024-03-09 22:36:20    0.0      1.0  2024-03-09 22:50:31    0.0  \n",
       "587   2024-03-09 22:36:58    0.0      1.0  2024-03-09 22:50:31    0.0  \n",
       "1189  2024-03-10 02:50:15    0.0      1.0  2024-03-10 02:54:24    0.0  \n",
       "\n",
       "[1190 rows x 8 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['reply'] = data.reply.astype(float)\n",
    "data['likenum'] = data.likenum.astype(float)\n",
    "data.loc[:,'hot'] = data.reply*data.likenum\n",
    "data.sort_values(by='hot', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_path = '/datb1/wuyuxuan/tmp/Holemonitor/data/2024-03-09_holes_monitor.db'\n",
    "with sqlite3.connect(db_path) as conn:\n",
    "    data_com = pd.read_sql(\"SELECT * FROM comments\", conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pid</th>\n",
       "      <th>text</th>\n",
       "      <th>type</th>\n",
       "      <th>time</th>\n",
       "      <th>reply</th>\n",
       "      <th>likenum</th>\n",
       "      <th>last_retrive</th>\n",
       "      <th>hot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>755</th>\n",
       "      <td>6037599</td>\n",
       "      <td>è¢«nanpyç”©äº†ï¼Œéš¾å—ï¼Œå¼€ä¸ªæ´popiğŸ˜­</td>\n",
       "      <td>text</td>\n",
       "      <td>2024-03-09 23:25:56</td>\n",
       "      <td>28.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2024-03-09 23:37:57</td>\n",
       "      <td>168.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         pid                  text  type                 time  reply  likenum   \n",
       "755  6037599  è¢«nanpyç”©äº†ï¼Œéš¾å—ï¼Œå¼€ä¸ªæ´popiğŸ˜­  text  2024-03-09 23:25:56   28.0      6.0  \\\n",
       "\n",
       "            last_retrive    hot  \n",
       "755  2024-03-09 23:37:57  168.0  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data.pid.isin(data_com[data_com.text.str.contains('fwb')].pid)].sort_values(by='time', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = \"\"\"\n",
    "6036940 deleted!\n",
    "6036940 deleted!\n",
    "6036940 deleted!\n",
    "6036940 deleted!\n",
    "6036940 deleted!\n",
    "6036940 deleted!\n",
    "6036940 deleted!\n",
    "6036940 deleted!\n",
    "6036940 deleted!\n",
    "6036980 deleted!\n",
    "6036940 deleted!\n",
    "6037025 deleted!\n",
    "6037171 deleted!\n",
    "6037180 deleted!\n",
    "6037258 deleted!\n",
    "6037367 deleted!\n",
    "6037345 deleted!\n",
    "6037812 deleted!\n",
    "6037876 deleted!\n",
    "6037921 deleted!\n",
    "6037937 deleted!\n",
    "\"\"\"\n",
    "deleted = re.findall(r'(\\d+) deleted!', s)\n",
    "deleted = [int(x) for x in deleted]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pid</th>\n",
       "      <th>text</th>\n",
       "      <th>type</th>\n",
       "      <th>time</th>\n",
       "      <th>reply</th>\n",
       "      <th>likenum</th>\n",
       "      <th>last_retrive</th>\n",
       "      <th>hot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>6036940</td>\n",
       "      <td>èŠèŠæœ€ç–¯çš„ç»å†ï¼Ÿ</td>\n",
       "      <td>text</td>\n",
       "      <td>2024-03-09 19:44:25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2024-03-09 20:05:31</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>6036980</td>\n",
       "      <td>è¹²é«˜ä¸€ç‰©ç†æ•°å­¦è€å¸ˆï¼Œåœ°ç‚¹å¤§å…´ï¼Œæ—¶è–ª160ã€‚QQ6537ï¸âƒ£7991ï¸âƒ£8</td>\n",
       "      <td>text</td>\n",
       "      <td>2024-03-09 20:02:20</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2024-03-09 20:04:01</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>6037025</td>\n",
       "      <td>å…¼èŒ å®¶æ•™</td>\n",
       "      <td>text</td>\n",
       "      <td>2024-03-09 20:14:49</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2024-03-09 20:16:44</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327</th>\n",
       "      <td>6037171</td>\n",
       "      <td>None</td>\n",
       "      <td>image</td>\n",
       "      <td>2024-03-09 21:07:59</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2024-03-09 21:14:10</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>6037180</td>\n",
       "      <td>è¿™è¾¹æœ‰ä¸ªé«˜ä¸‰æ•°å­¦çš„å•ï¼Œæ˜¯é‚£ç§çº¿ä¸Šè®²è§£é¢˜ç›®ï¼ŒæŒ‰é¢˜ç»™é’±çš„ã€‚æœ‰åŒå­¦æƒ³æ¥å—ï¼Œé¡ºä¾¿å¯ä»¥è¯´ä¸€ä¸‹ä»·æ ¼ã€‚</td>\n",
       "      <td>text</td>\n",
       "      <td>2024-03-09 21:09:53</td>\n",
       "      <td>17.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2024-03-09 21:16:50</td>\n",
       "      <td>102.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>6037258</td>\n",
       "      <td>æœ‰æœ¨æœ‰uuè®¤è¯†çš„å¤–æ ¡çš„uuæ„¿æ„åšåŠ©æ•™çš„ï¼Œçº¿ä¸‹æ”¹åˆä¸­ä½œä¸šé¢˜ï¼Œ200/å¤©</td>\n",
       "      <td>text</td>\n",
       "      <td>2024-03-09 21:45:14</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2024-03-09 21:49:00</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>6037345</td>\n",
       "      <td>å¤§å››å°è¯­ç§\\né€‰ä¸€çº¿åŸå¸‚å…¬åŠ¡å‘˜\\nè¿˜æ˜¯æµ·ç¡•ä¸€å¹´\\nï¼ˆç›®å‰æƒ…å†µæ˜¯ï¼Œæ”¶åˆ°äº†æ¸¯ä¸­æ–‡/æ¸¯å¤§å’Œå—æ´‹ç†å·¥...</td>\n",
       "      <td>text</td>\n",
       "      <td>2024-03-09 22:11:34</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2024-03-09 22:21:54</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>523</th>\n",
       "      <td>6037367</td>\n",
       "      <td>æ˜¨å¤©æ™šä¸Šè®©npyä¸€å¤œcumäº†ä¸‰æ¬¡</td>\n",
       "      <td>text</td>\n",
       "      <td>2024-03-09 22:19:03</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2024-03-09 22:20:23</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>967</th>\n",
       "      <td>6037812</td>\n",
       "      <td>æƒ³wen</td>\n",
       "      <td>text</td>\n",
       "      <td>2024-03-10 00:19:09</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2024-03-10 00:24:48</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1031</th>\n",
       "      <td>6037876</td>\n",
       "      <td>æœ‰æ²¡æœ‰ç›´ç”·æƒ³å¼¯ä¸€ä¸‹ æ‰¾æˆ‘</td>\n",
       "      <td>text</td>\n",
       "      <td>2024-03-10 00:44:46</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2024-03-10 00:49:04</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1076</th>\n",
       "      <td>6037921</td>\n",
       "      <td>åŒ—äº¬å¤§å­¦åŒ»å­¦éƒ¨å°±æ˜¯ç­”è¾©\\næ•™ä¹¦ç®€ç›´å°±æ˜¯ç­”è¾©\\nå»ºè®®å¼€é™¤ä¸€äº›è€å¸ˆ\\nèŠ±é’±æ‰¾ç‚¹ä¼šæ•™ä¹¦è‚²äººçš„æ¥ä¸è¡Œ...</td>\n",
       "      <td>text</td>\n",
       "      <td>2024-03-10 01:05:26</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2024-03-10 01:10:55</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1092</th>\n",
       "      <td>6037937</td>\n",
       "      <td>æ ‘æ´æ•æ„Ÿè¯éƒ½æœ‰å•¥å‘€ï¼Œæˆ‘åªæ˜¯æƒ³å‘è‡ªå·±å…³äºç™¾å…ƒä¹‹æ‹çš„å½±è¯„ï¼Œä¸ºå•¥å‘ä¸å‡ºæ¥å•Š</td>\n",
       "      <td>text</td>\n",
       "      <td>2024-03-10 01:13:01</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2024-03-10 01:21:10</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          pid                                               text   type   \n",
       "99    6036940                                           èŠèŠæœ€ç–¯çš„ç»å†ï¼Ÿ   text  \\\n",
       "137   6036980               è¹²é«˜ä¸€ç‰©ç†æ•°å­¦è€å¸ˆï¼Œåœ°ç‚¹å¤§å…´ï¼Œæ—¶è–ª160ã€‚QQ6537ï¸âƒ£7991ï¸âƒ£8   text   \n",
       "182   6037025                                              å…¼èŒ å®¶æ•™   text   \n",
       "327   6037171                                               None  image   \n",
       "336   6037180       è¿™è¾¹æœ‰ä¸ªé«˜ä¸‰æ•°å­¦çš„å•ï¼Œæ˜¯é‚£ç§çº¿ä¸Šè®²è§£é¢˜ç›®ï¼ŒæŒ‰é¢˜ç»™é’±çš„ã€‚æœ‰åŒå­¦æƒ³æ¥å—ï¼Œé¡ºä¾¿å¯ä»¥è¯´ä¸€ä¸‹ä»·æ ¼ã€‚   text   \n",
       "414   6037258                 æœ‰æœ¨æœ‰uuè®¤è¯†çš„å¤–æ ¡çš„uuæ„¿æ„åšåŠ©æ•™çš„ï¼Œçº¿ä¸‹æ”¹åˆä¸­ä½œä¸šé¢˜ï¼Œ200/å¤©   text   \n",
       "501   6037345  å¤§å››å°è¯­ç§\\né€‰ä¸€çº¿åŸå¸‚å…¬åŠ¡å‘˜\\nè¿˜æ˜¯æµ·ç¡•ä¸€å¹´\\nï¼ˆç›®å‰æƒ…å†µæ˜¯ï¼Œæ”¶åˆ°äº†æ¸¯ä¸­æ–‡/æ¸¯å¤§å’Œå—æ´‹ç†å·¥...   text   \n",
       "523   6037367                                   æ˜¨å¤©æ™šä¸Šè®©npyä¸€å¤œcumäº†ä¸‰æ¬¡   text   \n",
       "967   6037812                                               æƒ³wen   text   \n",
       "1031  6037876                                       æœ‰æ²¡æœ‰ç›´ç”·æƒ³å¼¯ä¸€ä¸‹ æ‰¾æˆ‘   text   \n",
       "1076  6037921  åŒ—äº¬å¤§å­¦åŒ»å­¦éƒ¨å°±æ˜¯ç­”è¾©\\næ•™ä¹¦ç®€ç›´å°±æ˜¯ç­”è¾©\\nå»ºè®®å¼€é™¤ä¸€äº›è€å¸ˆ\\nèŠ±é’±æ‰¾ç‚¹ä¼šæ•™ä¹¦è‚²äººçš„æ¥ä¸è¡Œ...   text   \n",
       "1092  6037937                 æ ‘æ´æ•æ„Ÿè¯éƒ½æœ‰å•¥å‘€ï¼Œæˆ‘åªæ˜¯æƒ³å‘è‡ªå·±å…³äºç™¾å…ƒä¹‹æ‹çš„å½±è¯„ï¼Œä¸ºå•¥å‘ä¸å‡ºæ¥å•Š   text   \n",
       "\n",
       "                     time  reply  likenum         last_retrive    hot  \n",
       "99    2024-03-09 19:44:25    1.0      1.0  2024-03-09 20:05:31    1.0  \n",
       "137   2024-03-09 20:02:20    2.0      2.0  2024-03-09 20:04:01    4.0  \n",
       "182   2024-03-09 20:14:49    4.0      3.0  2024-03-09 20:16:44   12.0  \n",
       "327   2024-03-09 21:07:59    1.0      2.0  2024-03-09 21:14:10    2.0  \n",
       "336   2024-03-09 21:09:53   17.0      6.0  2024-03-09 21:16:50  102.0  \n",
       "414   2024-03-09 21:45:14    2.0      3.0  2024-03-09 21:49:00    6.0  \n",
       "501   2024-03-09 22:11:34    2.0      4.0  2024-03-09 22:21:54    8.0  \n",
       "523   2024-03-09 22:19:03    2.0      3.0  2024-03-09 22:20:23    6.0  \n",
       "967   2024-03-10 00:19:09    4.0      3.0  2024-03-10 00:24:48   12.0  \n",
       "1031  2024-03-10 00:44:46    1.0      2.0  2024-03-10 00:49:04    2.0  \n",
       "1076  2024-03-10 01:05:26    6.0      5.0  2024-03-10 01:10:55   30.0  \n",
       "1092  2024-03-10 01:13:01   10.0      5.0  2024-03-10 01:21:10   50.0  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data.pid.isin(deleted)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "#ç”±äºç­›å‡ºæ¥å¤ªå¤šæ— æ„ä¹‰åœæ­¢è¯ï¼Œæ‰€ä»¥åŠ å…¥åœæ­¢è¯è¡¨ https://raw.githubusercontent.com/goto456/stopwords/master/baidu_stopwords.txt\n",
    "with open(\"baidu_stopwords.txt\") as f:\n",
    "    stop_word_list = f.read().splitlines()\n",
    "useless_str = '''ä¸€ï¼â€œâ€ï¼Œã€‚ï¼Ÿã€ï¼›â€™\"',.ã€Â·ã€Šã€‹ï¼ˆï¼‰()#\\tï¼š\\n\\r\\n/'''\n",
    "\n",
    "words = data['text'].progress_apply(lambda x: ' '.join([x for x in jieba.cut(x) if x not in stop_word_list and x not in useless_str]))\n",
    "data['raw_text'] = data['text'].copy()\n",
    "data['text'] = words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer()\n",
    "tfidf_vec = tfidf.fit_transform(data['text'])\n",
    "\n",
    "# Get the feature names from the vectorizer\n",
    "feature_names = tfidf.get_feature_names_out()\n",
    "\n",
    "# Get the sum of the tf-idf values for each feature across all documents\n",
    "sum_tfidf = np.sum(tfidf_vec.toarray(), axis=0)\n",
    "\n",
    "# Get the indices of the features sorted by their tf-idf sum in descending order\n",
    "sorted_indices = np.argsort(sum_tfidf)[::-1]\n",
    "\n",
    "# Print the top 10 features and their tf-idf sums\n",
    "print(\"Top 10 features and their tf-idf sums\")\n",
    "for i in range(10):\n",
    "    feature_index = sorted_indices[i]\n",
    "    feature_name = feature_names[feature_index]\n",
    "    tfidf_sum = sum_tfidf[feature_index]\n",
    "    print(f\"{feature_name}: {tfidf_sum}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word2Vec vectorization for segmented 'ç®€ä»‹'\n",
    "sentences = [s.split() for s in data['text']]\n",
    "\n",
    "seed = 123\n",
    "w2v = Word2Vec(sentences, vector_size=10, min_count=1, workers=4, seed=seed) # size is the dimensionality of the feature vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_path = '../data/2023-06-14_holes_monitor.db'\n",
    "with sqlite3.connect(db_path) as conn:\n",
    "    data_holes = pd.read_sql(\"SELECT * FROM holes\", conn)\n",
    "    data_comments = pd.read_sql(\"SELECT * FROM comments\", conn)\n",
    "\n",
    "data_holes.to_csv(\"../data/614holes.csv\", index=True)\n",
    "data_comments.to_csv(\"../data/614comments.csv\", index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_path = '../data/2023-06-19_holes_monitor.db'\n",
    "with sqlite3.connect(db_path) as conn:\n",
    "    data = pd.read_sql(\"SELECT * FROM holes\", conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kw = \".*(çŸ­ç§Ÿ|ç§Ÿæˆ¿).*\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data.text.str.match(kw, flags=re.DOTALL)]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
